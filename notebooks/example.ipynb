{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scengen.exp.experiment import ComparisonExperiment\n",
    "from scengen.generators import PredClusGenerator, SampleGenerator, RandomGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Util to generate random data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "random_gen = np.random.default_rng(12341)\n",
    "def random_dataset(N):\n",
    "    attributes = random_gen.random(size = (N, 25))\n",
    "    timeseries = random_gen.random(size = (N, 60))\n",
    "    folds = np.array_split(np.arange(0, N, dtype= 'int'), 5)\n",
    "    return attributes, timeseries, folds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment interface to easily run experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   0%|          | 0/3 [00:00<?, ?it/s, method=predictive_clustering]\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s, dataset=random_dataset]\u001B[A\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s, dataset=deep_random_dataset]\u001B[A\n",
      "Methods:   0%|          | 0/3 [00:00<?, ?it/s, method=deep_predictive_clustering]\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s, dataset=random_dataset]\u001B[A\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s, dataset=deep_random_dataset]\u001B[A\n",
      "Methods:   0%|          | 0/3 [00:00<?, ?it/s, method=random_baseline]           \n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Datasets:   0%|          | 0/2 [00:00<?, ?it/s, dataset=random_dataset]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "1it [00:00,  2.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:00,  3.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "3it [00:00,  4.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00,  4.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "5it [00:01,  4.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "Datasets:  50%|█████     | 1/2 [00:01<00:01,  1.23s/it, dataset=random_dataset]\u001B[A\n",
      "Datasets:  50%|█████     | 1/2 [00:01<00:01,  1.23s/it, dataset=deep_random_dataset]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "1it [00:02,  2.56s/it]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:04,  2.31s/it]\u001B[A\u001B[A\n",
      "\n",
      "3it [00:06,  2.21s/it]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:09,  2.25s/it]\u001B[A\u001B[A\n",
      "\n",
      "5it [00:11,  2.25s/it]\u001B[A\u001B[A\n",
      "\n",
      "Datasets: 100%|██████████| 2/2 [00:12<00:00,  7.12s/it, dataset=deep_random_dataset]\u001B[A\n",
      "Methods: 100%|██████████| 3/3 [00:12<00:00,  4.17s/it, method=random_baseline]      \u001B[A\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "experiment = (\n",
    "    ComparisonExperiment(result_path = Path('results/first_test'), nb_of_samples = 250)\n",
    "    .add_methods(\n",
    "        predictive_clustering =  PredClusGenerator(DecisionTreeRegressor(max_depth = 4, min_samples_leaf = 100)),\n",
    "        deep_predictive_clustering = PredClusGenerator(DecisionTreeRegressor(max_depth = 10, min_samples_leaf = 100)),\n",
    "        random_baseline = RandomGenerator(),\n",
    "    )\n",
    "    .add_datasets(\n",
    "        random_dataset = random_dataset(1000),\n",
    "        deep_random_dataset = random_dataset(10000)\n",
    "    )\n",
    ")\n",
    "\n",
    "energy_scores, timing_df = experiment.execute()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "predictive_clustering       random_dataset         1.600256\n                            deep_random_dataset    1.586180\ndeep_predictive_clustering  random_dataset         1.600099\n                            deep_random_dataset    1.595053\nrandom_baseline             random_dataset         1.587108\n                            deep_random_dataset    1.583526\ndtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_scores.mean(axis = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                training_time  predict_time  \\\npredictive_clustering      random_dataset            0.061019      0.050253   \n                           deep_random_dataset       0.954830      0.212758   \ndeep_predictive_clustering random_dataset            0.057783      0.035363   \n                           deep_random_dataset       1.554065      0.225117   \nrandom_baseline            random_dataset            0.001014      0.002900   \n                           deep_random_dataset       0.009206      0.016619   \n\n                                                eval_time  \npredictive_clustering      random_dataset        1.691875  \n                           deep_random_dataset  11.465797  \ndeep_predictive_clustering random_dataset        1.303460  \n                           deep_random_dataset  11.162136  \nrandom_baseline            random_dataset        1.209708  \n                           deep_random_dataset  11.206723  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>training_time</th>\n      <th>predict_time</th>\n      <th>eval_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">predictive_clustering</th>\n      <th>random_dataset</th>\n      <td>0.061019</td>\n      <td>0.050253</td>\n      <td>1.691875</td>\n    </tr>\n    <tr>\n      <th>deep_random_dataset</th>\n      <td>0.954830</td>\n      <td>0.212758</td>\n      <td>11.465797</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">deep_predictive_clustering</th>\n      <th>random_dataset</th>\n      <td>0.057783</td>\n      <td>0.035363</td>\n      <td>1.303460</td>\n    </tr>\n    <tr>\n      <th>deep_random_dataset</th>\n      <td>1.554065</td>\n      <td>0.225117</td>\n      <td>11.162136</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">random_baseline</th>\n      <th>random_dataset</th>\n      <td>0.001014</td>\n      <td>0.002900</td>\n      <td>1.209708</td>\n    </tr>\n    <tr>\n      <th>deep_random_dataset</th>\n      <td>0.009206</td>\n      <td>0.016619</td>\n      <td>11.206723</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use model directly\n",
    "PredClusGenerator return indices into the training data as samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[335, 393,  17, 665, 925, 600, 224, 444, 966, 733, 750, 195, 393,\n        280, 109, 195, 976, 910, 491, 505, 109, 552, 220, 840,   1, 539,\n        881, 334, 335, 718, 915, 881,  65, 730, 888, 600, 730, 970, 793,\n        974, 749, 811, 840, 974, 749, 792, 750, 419, 515, 172, 981, 728,\n        297, 280,  62,  17, 973, 379, 297, 619, 582, 280, 109,  56, 468,\n        696, 720, 903, 718, 239, 868, 155, 900, 366, 444,  97, 492, 712,\n        491, 220, 973, 994, 951, 999, 285, 814, 701, 109, 223, 588, 712,\n        888, 235, 973, 365, 649, 968, 300, 974, 419]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  PredClusGenerator(DecisionTreeRegressor(max_depth = 4, min_samples_leaf = 100))\n",
    "attributes, timeseries, _ = random_dataset(1000)\n",
    "model.fit(attributes, timeseries)\n",
    "\n",
    "test_attributes = np.random.random(size = (1, attributes.shape[1]))\n",
    "indices = model.generate(test_attributes, nb_of_samples=100)\n",
    "indices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.78917159, 0.29641053, 0.88647886, ..., 0.31124221,\n         0.49443381, 0.00291426],\n        [0.37260943, 0.62400753, 0.00716524, ..., 0.45125638,\n         0.82006294, 0.20655288],\n        [0.29781456, 0.08027319, 0.69547696, ..., 0.49901803,\n         0.99129198, 0.5225916 ],\n        ...,\n        [0.59350444, 0.99189365, 0.57016508, ..., 0.12343996,\n         0.09424864, 0.57252782],\n        [0.36438214, 0.32872846, 0.01873795, ..., 0.00198167,\n         0.63073099, 0.66979514],\n        [0.91221482, 0.31460003, 0.03629783, ..., 0.94277473,\n         0.81787294, 0.76477122]]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries[indices]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Or use SampleGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.50949858, 0.03405682, 0.82178775, ..., 0.82794544,\n         0.68002814, 0.1131569 ],\n        [0.53663628, 0.63484605, 0.29854691, ..., 0.17171469,\n         0.70286616, 0.39224721],\n        [0.76924495, 0.82666538, 0.55089984, ..., 0.43513758,\n         0.78075136, 0.18882439],\n        ...,\n        [0.33166547, 0.8048977 , 0.5573701 , ..., 0.97335676,\n         0.26030587, 0.07771656],\n        [0.63312946, 0.5382988 , 0.75668396, ..., 0.20077779,\n         0.45015677, 0.77075608],\n        [0.86713973, 0.96776444, 0.76527476, ..., 0.5031114 ,\n         0.20024022, 0.9533432 ]]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  SampleGenerator(PredClusGenerator(DecisionTreeRegressor(max_depth = 4, min_samples_leaf = 100)))\n",
    "attributes, timeseries, _ = random_dataset(1000)\n",
    "model.fit(attributes, timeseries)\n",
    "\n",
    "test_attributes = np.random.random(size = (1, attributes.shape[1]))\n",
    "timeseries = model.generate_timeseries(test_attributes, nb_of_samples=100)\n",
    "timeseries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "admercs",
   "language": "python",
   "display_name": "admercs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
